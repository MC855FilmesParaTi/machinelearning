{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Treinado\n",
    "\n",
    "Neste notebook, encontramos um modelo já treinado e só estamos usando os pesos que obtivemos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3067,
     "status": "ok",
     "timestamp": 1669139721296,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "-uC_ohs2-dGc",
    "outputId": "eaa56059-5e75-4a6b-d6e1-3a4dfcd90472"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1669139721304,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "RWIIBNkaeePB",
    "outputId": "f4d5278b-27aa-456a-818b-8a266afe3747"
   },
   "outputs": [],
   "source": [
    "cd drive/Shareddrives/Filmes Pra TI - Machine Learning/Modelo_Marcela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2615,
     "status": "ok",
     "timestamp": 1669139733440,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "Np_J2YMW-9ys"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import shutil\n",
    "# import papermill as pm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from reco_utils.recommender.ncf.dataset import Dataset as NCFDataset\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_chrono_split\n",
    "from reco_utils.evaluation.python_evaluation import (rmse, mae, rsquared, exp_var, map_at_k, ndcg_at_k, precision_at_k, \n",
    "                                                     recall_at_k, get_top_k_items)\n",
    "from reco_utils.common.constants import SEED as DEFAULT_SEED\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 854,
     "status": "ok",
     "timestamp": 1669139734289,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "Zo4Q2VBwEsnS"
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as v1\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class NCF:\n",
    "    \"\"\"NCF implementation\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users,\n",
    "        n_items,\n",
    "        model_type=\"NeuMF\",\n",
    "        random_state=0,\n",
    "        n_factors=8,\n",
    "        layer_sizes=[16, 8, 4],\n",
    "        n_epochs=50,\n",
    "        batch_size=512,\n",
    "        learning_rate=5e-3,\n",
    "        verbose=1,\n",
    "        save=False,\n",
    "        pretrain=False,\n",
    "        seed=42,\n",
    "        ckpt_file='model.ckpt'\n",
    "    ):\n",
    "        # number of users in dataset\n",
    "        self.n_users = n_users\n",
    "        # number of items in dataset\n",
    "        self.n_items = n_items\n",
    "        # model type\n",
    "        self.model_type = model_type.lower()\n",
    "\n",
    "        # filename of the model\n",
    "        self.ckpt_file = ckpt_file\n",
    "        # check model type\n",
    "        model_options = [\"gmf\", \"mlp\", \"neumf\"]\n",
    "        if self.model_type not in model_options:\n",
    "            raise ValueError(\n",
    "                \"Wrong model type, please select one of this list: {}\".format(\n",
    "                    model_options\n",
    "                )\n",
    "            )\n",
    "        # seed\n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        # dimension of latent space\n",
    "        self.n_factors = n_factors\n",
    "        # number of layers for mlp\n",
    "        self.layer_sizes = layer_sizes\n",
    "        # number of epochs for training\n",
    "        self.n_epochs = n_epochs\n",
    "        # training output or not\n",
    "        self.verbose = verbose\n",
    "        # set batch size\n",
    "        self.batch_size = batch_size\n",
    "        # set learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "        # ncf layer input size\n",
    "        self.ncf_layer_size = n_factors + layer_sizes[-1]\n",
    "        # create ncf model\n",
    "        self._create_model()\n",
    "        # set GPU use with demand growth\n",
    "        gpu_options = v1.GPUOptions(allow_growth=True)\n",
    "        # set TF Session\n",
    "        self.sess = v1.Session(config=v1.ConfigProto(gpu_options=gpu_options))\n",
    "        # parameters initialization\n",
    "        self.sess.run(v1.global_variables_initializer())\n",
    "\n",
    "    def _create_model(self,):\n",
    "        # reset graph\n",
    "        from tensorflow.python.framework import ops\n",
    "        ops.reset_default_graph()\n",
    "\n",
    "        with tf.compat.v1.variable_scope(\"input_data\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "\n",
    "            # input: index of users, items and ground truth\n",
    "            self.user_input = v1.placeholder(tf.int32, shape=[None, 1])\n",
    "            self.item_input = v1.placeholder(tf.int32, shape=[None, 1])\n",
    "            self.labels = v1.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "        with v1.variable_scope(\"embedding\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "\n",
    "            # set embedding table\n",
    "            self.embedding_gmf_P = tf.Variable(\n",
    "                v1.truncated_normal(\n",
    "                    shape=[self.n_users, self.n_factors], mean=0.0, stddev=0.01\n",
    "                ),\n",
    "                name=\"embedding_gmf_P\",\n",
    "                dtype=tf.float32,\n",
    "            )\n",
    "\n",
    "            self.embedding_gmf_Q = tf.Variable(\n",
    "                v1.truncated_normal(\n",
    "                    shape=[self.n_items, self.n_factors], mean=0.0, stddev=0.01\n",
    "                ),\n",
    "                name=\"embedding_gmf_Q\",\n",
    "                dtype=tf.float32,\n",
    "            )\n",
    "\n",
    "            # set embedding table\n",
    "            self.embedding_mlp_P = tf.Variable(\n",
    "                v1.truncated_normal(\n",
    "                    shape=[self.n_users, int(self.layer_sizes[0] / 2)],\n",
    "                    mean=0.0,\n",
    "                    stddev=0.01,\n",
    "                ),\n",
    "                name=\"embedding_mlp_P\",\n",
    "                dtype=tf.float32,\n",
    "            )\n",
    "\n",
    "            self.embedding_mlp_Q = tf.Variable(\n",
    "                v1.truncated_normal(\n",
    "                    shape=[self.n_items, int(self.layer_sizes[0] / 2)],\n",
    "                    mean=0.0,\n",
    "                    stddev=0.01,\n",
    "                ),\n",
    "                name=\"embedding_mlp_Q\",\n",
    "                dtype=tf.float32,\n",
    "            )\n",
    "\n",
    "        with tf.compat.v1.variable_scope(\"gmf\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "\n",
    "            # get user embedding p and item embedding q\n",
    "            self.gmf_p = tf.reduce_sum(\n",
    "                tf.nn.embedding_lookup(self.embedding_gmf_P, self.user_input), 1\n",
    "            )\n",
    "            self.gmf_q = tf.reduce_sum(\n",
    "                tf.nn.embedding_lookup(self.embedding_gmf_Q, self.item_input), 1\n",
    "            )\n",
    "\n",
    "            # get gmf vector\n",
    "            self.gmf_vector = self.gmf_p * self.gmf_q\n",
    "\n",
    "        with tf.compat.v1.variable_scope(\"mlp\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "\n",
    "            # get user embedding p and item embedding q\n",
    "            self.mlp_p = tf.reduce_sum(\n",
    "                tf.nn.embedding_lookup(self.embedding_mlp_P, self.user_input), 1\n",
    "            )\n",
    "            self.mlp_q = tf.reduce_sum(\n",
    "                tf.nn.embedding_lookup(self.embedding_mlp_Q, self.item_input), 1\n",
    "            )\n",
    "\n",
    "            # concatenate user and item vector\n",
    "            output = tf.concat([self.mlp_p, self.mlp_q], 1)\n",
    "\n",
    "            # MLP Layers\n",
    "            for layer_size in self.layer_sizes[1:]:\n",
    "                output = v1.layers.dense(\n",
    "                    output, layer_size, activation=tf.nn.relu\n",
    "                )\n",
    "            self.mlp_vector = output\n",
    "\n",
    "            # self.output = tf.sigmoid(tf.reduce_sum(self.mlp_vector, axis=1, keepdims=True))\n",
    "\n",
    "        with tf.compat.v1.variable_scope(\"ncf\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "\n",
    "            if self.model_type == \"gmf\":\n",
    "                # GMF only\n",
    "                output = v1.layers.dense(\n",
    "                    self.gmf_vector,\n",
    "                    1,\n",
    "                    activation=None,\n",
    "                    biases_initializer=None,\n",
    "                )\n",
    "                self.output = tf.sigmoid(output)\n",
    "\n",
    "            elif self.model_type == \"mlp\":\n",
    "                # MLP only\n",
    "                output = v1.layers.dense(\n",
    "                    self.mlp_vector,\n",
    "                    1,\n",
    "                    activation=None,\n",
    "                    bias_initializer=None,\n",
    "                )\n",
    "                self.output = tf.sigmoid(output)\n",
    "\n",
    "            elif self.model_type == \"neumf\":\n",
    "                # concatenate GMF and MLP vector\n",
    "                self.ncf_vector = tf.concat([self.gmf_vector, self.mlp_vector], 1)\n",
    "                # get predicted rating score\n",
    "                output = v1.layers.dense(\n",
    "                    self.ncf_vector,\n",
    "                    1,\n",
    "                    activation=None,\n",
    "                    bias_initializer=None,\n",
    "                )\n",
    "                self.output = tf.sigmoid(output)\n",
    "\n",
    "        with v1.variable_scope(\"loss\", reuse=v1.AUTO_REUSE):\n",
    "\n",
    "            # set loss function\n",
    "            self.loss = v1.losses.log_loss(self.labels, self.output)\n",
    "\n",
    "        with v1.variable_scope(\"optimizer\", reuse=v1.AUTO_REUSE):\n",
    "\n",
    "            # set optimizer\n",
    "            self.optimizer = v1.train.AdamOptimizer(\n",
    "                learning_rate=self.learning_rate\n",
    "            ).minimize(self.loss)\n",
    "\n",
    "    def save(self, dir_name):\n",
    "        \"\"\" save model parameters in `dir_name`\n",
    "            Args:\n",
    "                dir_name (str) : directory name, which should be folder name instead of file name\n",
    "                    we will create a new directory if not existing.\n",
    "        \"\"\"\n",
    "        # save trained model\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.makedirs(dir_name)\n",
    "        saver = tf.compat.v1.train.Saver()\n",
    "        saver.save(self.sess, os.path.join(dir_name, self.ckpt_file))\n",
    "\n",
    "    def load(self, gmf_dir=None, mlp_dir=None, neumf_dir=None, alpha=0.5):\n",
    "        \"\"\" load model parameters for further use.\n",
    "            GMF model --> load parameters in `gmf_dir`\n",
    "            MLP model --> load parameters in `mlp_dir`\n",
    "            NeuMF model --> load parameters in `neumf_dir` or in `gmf_dir` and `mlp_dir`\n",
    "            Args:\n",
    "                gmf_dir, mlp_dir, neumf_dir ( str or None ): model parameters directory name\n",
    "            Returns:\n",
    "                load parameters in this model\n",
    "        \"\"\"\n",
    "\n",
    "        # load pre-trained model\n",
    "        if self.model_type == \"gmf\" and gmf_dir is not None:\n",
    "            saver = tf.compat.v1.train.Saver()\n",
    "            saver.restore(self.sess, os.path.join(gmf_dir, self.ckpt_file))\n",
    "\n",
    "        elif self.model_type == \"mlp\" and mlp_dir is not None:\n",
    "            saver = tf.compat.v1.train.Saver()\n",
    "            saver.restore(self.sess, os.path.join(mlp_dir, self.ckpt_file))\n",
    "\n",
    "        elif self.model_type == \"neumf\" and neumf_dir is not None:\n",
    "            saver = tf.compat.v1.train.Saver()\n",
    "            saver.restore(self.sess, os.path.join(neumf_dir, self.ckpt_file))\n",
    "\n",
    "        elif self.model_type == \"neumf\" and gmf_dir is not None and mlp_dir is not None:\n",
    "            # load neumf using gmf and mlp\n",
    "            self._load_neumf(gmf_dir, mlp_dir, alpha)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def _load_neumf(self, gmf_dir, mlp_dir, alpha):\n",
    "        \"\"\" load gmf and mlp model parameters for further use in NeuMF.\n",
    "            NeuMF model --> load parameters in `gmf_dir` and `mlp_dir`\n",
    "            Args:\n",
    "                gmf_dir, mlp_dir ( str or None ): model parameters directory name\n",
    "                alpha ( float ): the concatenation hyper-parameter for gmf and mlp output layer\n",
    "            Returns:\n",
    "                load parameters in NeuMF model\n",
    "        \"\"\"\n",
    "        # load gmf part\n",
    "        variables = tf.global_variables()\n",
    "        # get variables with 'gmf'\n",
    "        var_flow_restore = [\n",
    "            val for val in variables if \"gmf\" in val.name and \"ncf\" not in val.name\n",
    "        ]\n",
    "        # load 'gmf' variable\n",
    "        saver = tf.compat.v1.train.Saver(var_flow_restore)\n",
    "        # restore\n",
    "        saver.restore(self.sess, os.path.join(gmf_dir, self.ckpt_file))\n",
    "\n",
    "        # load mlp part\n",
    "        variables = v1.global_variables()\n",
    "        # get variables with 'gmf'\n",
    "        var_flow_restore = [\n",
    "            val for val in variables if \"mlp\" in val.name and \"ncf\" not in val.name\n",
    "        ]\n",
    "        # load 'gmf' variable\n",
    "        saver = tf.compat.v1.train.Saver(var_flow_restore)\n",
    "        # restore\n",
    "        saver.restore(self.sess, os.path.join(mlp_dir, self.ckpt_file))\n",
    "\n",
    "        # concat pretrain h_from_gmf and h_from_mlp\n",
    "        vars_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"ncf\")\n",
    "\n",
    "        assert len(vars_list) == 1\n",
    "        ncf_fc = vars_list[0]\n",
    "\n",
    "        # get weight from gmf and mlp\n",
    "        gmf_fc = tf.contrib.framework.load_variable(gmf_dir, ncf_fc.name)\n",
    "        mlp_fc = tf.contrib.framework.load_variable(mlp_dir, ncf_fc.name)\n",
    "\n",
    "        # load fc layer by tf.concat\n",
    "        assign_op = tf.assign(\n",
    "            ncf_fc, tf.concat([alpha * gmf_fc, (1 - alpha) * mlp_fc], axis=0)\n",
    "        )\n",
    "        self.sess.run(assign_op)\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\" fit model with training data\n",
    "            \n",
    "            Args: \n",
    "                data ( NCFDataset ): initilized Dataset in ./dataset.py\n",
    "        \"\"\"\n",
    "\n",
    "        # get user and item mapping dict\n",
    "        self.user2id = data.user2id\n",
    "        self.item2id = data.item2id\n",
    "        self.id2user = data.id2user\n",
    "        self.id2item = data.id2item\n",
    "\n",
    "        # loop for n_epochs\n",
    "        for epoch_count in range(1, self.n_epochs + 1):\n",
    "\n",
    "            # negative sampling for training\n",
    "            train_begin = time()\n",
    "            data.negative_sampling()\n",
    "\n",
    "            # initialize\n",
    "            train_loss = []\n",
    "\n",
    "            # calculate loss and update NCF parameters\n",
    "            for user_input, item_input, labels in data.train_loader(self.batch_size):\n",
    "\n",
    "                user_input = np.array([data.user2id[x] for x in user_input])\n",
    "                item_input = np.array([data.item2id[x] for x in item_input])\n",
    "                labels = np.array(labels)\n",
    "\n",
    "                feed_dict = {\n",
    "                    self.user_input: user_input[..., None],\n",
    "                    self.item_input: item_input[..., None],\n",
    "                    self.labels: labels[..., None],\n",
    "                }\n",
    "\n",
    "                # get loss and execute optimization\n",
    "                loss, _ = self.sess.run([self.loss, self.optimizer], feed_dict)\n",
    "                train_loss.append(loss)\n",
    "            train_time = time() - train_begin\n",
    "\n",
    "            # output every self.verbose\n",
    "            if self.verbose and epoch_count % self.verbose == 0:\n",
    "                logger.info(\n",
    "                    \"Epoch %d [%.2fs]: train_loss = %.6f \"\n",
    "                    % (epoch_count, train_time, sum(train_loss) / len(train_loss))\n",
    "                )\n",
    "\n",
    "    def predict(self, user_input, item_input, user2id, item2id, is_list=False):\n",
    "        \"\"\" predict function of this trained model\n",
    "            Args:\n",
    "                user_input ( list or element of list ): userID or userID list \n",
    "                item_input ( list or element of list ): itemID or itemID list\n",
    "                is_list ( bool ): if true, the input is list type\n",
    "                noting that list-wise type prediction is faster than element-wise's.\n",
    "            Returns:\n",
    "                list or float: list of predicted rating or predicted rating score. \n",
    "        \"\"\"\n",
    "\n",
    "        if is_list:\n",
    "            output = self._predict(user_input, item_input, user2id, item2id)\n",
    "            return list(output.reshape(-1))\n",
    "\n",
    "        else:\n",
    "            output = self._predict(np.array([user_input]), np.array([item_input]), user2id, item2id)\n",
    "            return float(output.reshape(-1)[0])\n",
    "\n",
    "    def _predict(self, user_input, item_input, user2id, item2id):\n",
    "\n",
    "        # index converting\n",
    "        user_input = np.array([user2id[x] for x in user_input])\n",
    "        item_input = np.array([item2id[x] for x in item_input])\n",
    "\n",
    "        # get feed dict\n",
    "        feed_dict = {\n",
    "            self.user_input: user_input[..., None],\n",
    "            self.item_input: item_input[..., None],\n",
    "        }\n",
    "\n",
    "        # calculate predicted score\n",
    "        output = self.sess.run(self.output, feed_dict)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 6047,
     "status": "ok",
     "timestamp": 1669048573768,
     "user": {
      "displayName": "Luana Barros",
      "userId": "07684200440933696182"
     },
     "user_tz": 180
    },
    "id": "vFyXTbBkFi8a",
    "outputId": "b0de03f4-3cc9-4b00-e3bf-18f6431ac012"
   },
   "outputs": [],
   "source": [
    "ml_1m = pd.read_csv('ratings_1M.dat', sep = \"::\",\n",
    "    names = [\"userID\", \"itemID\", \"rating\", \"timestamp\"],\n",
    ")\n",
    "ml_1m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1669141008883,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "16S5xO2HDBRh",
    "outputId": "b6cc426c-3f25-4ce5-9842-12360dad2bcd"
   },
   "outputs": [],
   "source": [
    "rating_100k = pd.read_csv('ratings_100k.csv')\n",
    "rating_100k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1669141008886,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "wZzrThWWFAQi"
   },
   "outputs": [],
   "source": [
    "rating_100k.rename(columns={'movieId':'itemID', 'userId':'userID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 2420,
     "status": "ok",
     "timestamp": 1669141011290,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "jZCz_zCpDMJ3",
    "outputId": "8ad73bd3-e173-48fb-919d-f3ca95eb674c"
   },
   "outputs": [],
   "source": [
    "# col_user ='userId', col_item = 'movieId', col_timestamp ='timestamp'\n",
    "train, test = python_chrono_split(rating_100k, 0.75)\n",
    "train['rating'] = np.where(train['rating']>2.5, 1, 0)\n",
    "test['rating'] = np.where(test['rating']>2.5, 1, 0)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yWZ6H3_nVjn"
   },
   "outputs": [],
   "source": [
    "train.to_csv('train_ratings_100k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8616,
     "status": "ok",
     "timestamp": 1669141023906,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "GMAFy-bVC1_I"
   },
   "outputs": [],
   "source": [
    "seed = 710\n",
    "TOP_K = 10\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'\n",
    "\n",
    "# Model parameters\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "seed=710  # Set None for non-deterministic results\n",
    "data = NCFDataset(train=train, test=test, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1669139754848,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "PN7ZtTzf3QZV",
    "outputId": "f5671d4e-bd84-4569-e13e-359903dc71d0"
   },
   "outputs": [],
   "source": [
    "set(train['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1669139858830,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "rooWDpxU_NGX",
    "outputId": "5484d87c-dfd8-407e-cd64-f74bd533e4ac"
   },
   "outputs": [],
   "source": [
    "model = NCF(n_users=data.n_users,n_items=data.n_items,model_type=\"NeuMF\",n_factors=4,layer_sizes=[16,8,4],\\\n",
    "            n_epochs=EPOCHS,batch_size=BATCH_SIZE,learning_rate=1e-3,verbose=10,seed=seed, ckpt_file='model_100k.ckpt')\n",
    "# n_factors (int): Dimension of latent space.\n",
    "# layer_sizes (list): Number of layers for MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1669139858831,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "bSJu5lVCfIBh"
   },
   "outputs": [],
   "source": [
    "# if want to load a previous model\n",
    "model.load(neumf_dir='model_100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkWtaBeEa_vR"
   },
   "outputs": [],
   "source": [
    "# training the model\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 27140,
     "status": "ok",
     "timestamp": 1669054952011,
     "user": {
      "displayName": "Luana Barros",
      "userId": "07684200440933696182"
     },
     "user_tz": 180
    },
    "id": "006mwTJ0VdBJ",
    "outputId": "564cd3ec-b5da-462f-cd8b-f2269b7f701c"
   },
   "outputs": [],
   "source": [
    "predictions = [[row.userID, row.itemID, model.predict(row.userID, row.itemID, data.user2id, data.item2id)]\n",
    "               for (_, row) in test.iterrows()]\n",
    "\n",
    "# saving the predictions in a dataframe\n",
    "predictions = pd.DataFrame(predictions, columns=['userID', 'itemID', 'prediction'])\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZu_Cu1eBvl9"
   },
   "outputs": [],
   "source": [
    "users, items, preds = [], [], []\n",
    "item = list(train.itemID.unique())\n",
    "for user in train.userID.unique():\n",
    "    user = [user] * len(item) \n",
    "    users.extend(user)\n",
    "    items.extend(item)\n",
    "    preds.extend(list(model.predict(user, item, data.user2id, data.item2id, is_list=True)))\n",
    "\n",
    "all_predictions = pd.DataFrame(data={\"userID\": users, \"itemID\":items, \"prediction\":preds})\n",
    "\n",
    "merged = pd.merge(train, all_predictions, on=[\"userID\", \"itemID\"], how=\"outer\")\n",
    "all_predictions = merged[merged.rating.isnull()].drop('rating', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3081,
     "status": "ok",
     "timestamp": 1669140759395,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "cmJZsKoYikzQ"
   },
   "outputs": [],
   "source": [
    "# all_predictions_100k = pd.read_csv('all_predictions_100k.csv')\n",
    "all_predictions_100k = all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1669140759398,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "TJI6KePu-C6U",
    "outputId": "07c3de53-bc35-46fb-b502-06118efeee44"
   },
   "outputs": [],
   "source": [
    "all_predictions_100k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1809,
     "status": "ok",
     "timestamp": 1669140768511,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "5bJkSPgKiKpg"
   },
   "outputs": [],
   "source": [
    "all_predictions_100k['binary_prediction'] = all_predictions_100k.prediction.apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1669140777183,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "M4lyMSbqivY6",
    "outputId": "b6edfa02-ce69-48cb-a460-33f738ef32e7"
   },
   "outputs": [],
   "source": [
    "all_predictions_100k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15086,
     "status": "ok",
     "timestamp": 1669140798910,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "hZWxbRKD-ImW"
   },
   "outputs": [],
   "source": [
    "all_predictions_100k.to_csv('all_predictions_100k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 846,
     "status": "ok",
     "timestamp": 1669141740914,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "Cf0t29HpkgTI"
   },
   "outputs": [],
   "source": [
    "TOP_K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38466,
     "status": "ok",
     "timestamp": 1669141779902,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "W2KbrQVsi9J8"
   },
   "outputs": [],
   "source": [
    "eval_map = map_at_k(test, all_predictions_100k, col_prediction='binary_prediction', k=TOP_K)\n",
    "eval_ndcg = ndcg_at_k(test, all_predictions_100k, col_prediction='binary_prediction', k=TOP_K)\n",
    "eval_precision = precision_at_k(test, all_predictions_100k, col_prediction='binary_prediction', k=TOP_K)\n",
    "eval_recall = recall_at_k(test, all_predictions_100k, col_prediction='binary_prediction', k=TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1669141782207,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "JsKkluOojNlr",
    "outputId": "9f8993f6-f9e6-4723-fc9b-df4bdabdaa7a"
   },
   "outputs": [],
   "source": [
    "eval_map, eval_ndcg, eval_precision, eval_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tZmqn6DcU9Q"
   },
   "source": [
    "Trazendo recomendações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ficJnq6FcJA_"
   },
   "outputs": [],
   "source": [
    "recs = all_predictions[all_predictions.userID == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1669055308934,
     "user": {
      "displayName": "Luana Barros",
      "userId": "07684200440933696182"
     },
     "user_tz": 180
    },
    "id": "0OGnWaGDccnD",
    "outputId": "fe894be3-21fc-4e67-b0e2-4fcb60d509f0"
   },
   "outputs": [],
   "source": [
    "recs.sort_values(by='prediction', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLbU_katld5N"
   },
   "source": [
    "Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSp5HdoKMHX3"
   },
   "outputs": [],
   "source": [
    "model.save(dir_name=\"model_100k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJAwaLVCXcI7"
   },
   "source": [
    "Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1669055718220,
     "user": {
      "displayName": "Luana Barros",
      "userId": "07684200440933696182"
     },
     "user_tz": 180
    },
    "id": "ZQjIifZOeQd2",
    "outputId": "8db612b8-d131-4c93-ff99-e44c8c0839d6"
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1669139770267,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "HdC4ovRyOAu8",
    "outputId": "e4e77110-49c0-4adc-be10-c19854ea1bac"
   },
   "outputs": [],
   "source": [
    "model2 = NCF(n_users=data.n_users,n_items=data.n_items,model_type=\"NeuMF\", ckpt_file='model_100k.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1669139772956,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "6rSRRMIdMmex"
   },
   "outputs": [],
   "source": [
    "model2.load(neumf_dir='model_100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOMdfOmtTp7B"
   },
   "outputs": [],
   "source": [
    "predictions_teste = [[row.userID, row.itemID, model2.predict(row.userID, row.itemID, data.user2id, data.item2id)]\n",
    "               for (_, row) in test.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1669053997815,
     "user": {
      "displayName": "Luana Barros",
      "userId": "07684200440933696182"
     },
     "user_tz": 180
    },
    "id": "Hg15dhkfSi3b",
    "outputId": "fd3aaa6b-3417-4217-df2e-fa7a1972935d"
   },
   "outputs": [],
   "source": [
    "predictions_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fuhe2R2FfiNJ"
   },
   "source": [
    "Metrics of 1M model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8655,
     "status": "ok",
     "timestamp": 1669139999368,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "kRaAEmxPflMm"
   },
   "outputs": [],
   "source": [
    "all_predictions_1M = pd.read_csv('all_predictions_1M.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9234,
     "status": "ok",
     "timestamp": 1669141114639,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "Ed749AtDj9KW"
   },
   "outputs": [],
   "source": [
    "all_predictions_1M['binary_prediction'] = all_predictions_1M.prediction.apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1669141115804,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "iUZJaC_ekBEl",
    "outputId": "173613ee-4a3a-47ed-b1a2-cb6eb37ef245"
   },
   "outputs": [],
   "source": [
    "all_predictions_1M.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 181128,
     "status": "ok",
     "timestamp": 1669141296924,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "AQszAVDqfkdX"
   },
   "outputs": [],
   "source": [
    "eval_map = map_at_k(test, all_predictions_1M, col_prediction='prediction', k=TOP_K)\n",
    "eval_ndcg = ndcg_at_k(test, all_predictions_1M, col_prediction='prediction', k=TOP_K)\n",
    "eval_precision = precision_at_k(test, all_predictions_1M, col_prediction='prediction', k=TOP_K)\n",
    "eval_recall = recall_at_k(test, all_predictions_1M, col_prediction='prediction', k=TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1669141296927,
     "user": {
      "displayName": "Luana Barros",
      "userId": "12406417690265903431"
     },
     "user_tz": 180
    },
    "id": "dOgSTAK0fu9m",
    "outputId": "fb02b362-00ea-4aca-d75b-59318d4eb7e7"
   },
   "outputs": [],
   "source": [
    "eval_map, eval_ndcg, eval_precision, eval_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yLe8lKWJgcE7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
